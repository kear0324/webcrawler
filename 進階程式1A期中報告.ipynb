{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CBwovkfsmtJ"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4 selenium webdriver-manager\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "urls = [\n",
        "    \"https://csie.asia.edu.tw/zh_tw/TeacherIntroduction/Full_time_faculty\",\n",
        "    \"https://csie.asia.edu.tw/zh_tw/TeacherIntroduction/Full_time_professor\",\n",
        "    \"https://csie.asia.edu.tw/zh_tw/TeacherIntroduction/Full_time_Associate_Professor\",\n",
        "    \"https://csie.asia.edu.tw/zh_tw/TeacherIntroduction/Full_time_Assistant_Professor\",\n",
        "    \"https://csie.asia.edu.tw/zh_tw/TeacherIntroduction/Full_time_Lecturer\",\n",
        "    \"https://csie.asia.edu.tw/zh_tw/TeacherIntroduction/Part_time_faculty\"\n",
        "]\n",
        "db_filename = \"teacher_research_areas_combined.db\"\n",
        "txt_filename = \"all_teacher_research_areas_combined.txt\"\n",
        "use_selenium = True\n",
        "\n",
        "conn = sqlite3.connect(db_filename)\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS teachers (\n",
        "    url TEXT,\n",
        "    name TEXT,\n",
        "    research_area TEXT,\n",
        "    method TEXT  -- 記錄爬取方法 (requests/selenium)\n",
        ")\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "\n",
        "all_teacher_research_areas_txt = \"\"\n",
        "\n",
        "if use_selenium:\n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    try:\n",
        "        driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_options)\n",
        "    except Exception as e:\n",
        "        print(f\"Selenium WebDriver 初始化失敗：{e}\")\n",
        "        use_selenium = False\n",
        "        print(\"將嘗試使用 requests 和 BeautifulSoup 進行爬蟲。\")\n",
        "else:\n",
        "    driver = None\n",
        "\n",
        "for url in urls:\n",
        "    print(f\"正在爬取：{url} (使用 {'Selenium' if use_selenium else 'requests'})\")\n",
        "    all_teacher_research_areas_txt += f\"--- {url} (使用 {'Selenium' if use_selenium else 'requests'}) ---\\n\"\n",
        "    try:\n",
        "        if use_selenium and driver:\n",
        "            driver.get(url)\n",
        "            time.sleep(3)\n",
        "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        else:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "            response.encoding = 'utf-8'\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        teacher_items = soup.find_all('div', class_='i-member-item')\n",
        "\n",
        "        for item in teacher_items:\n",
        "            name_span = item.find('span', class_='member-data-value-name')\n",
        "            research_area_span = item.find('span', class_='member-data-value-7')\n",
        "\n",
        "            if name_span and research_area_span:\n",
        "                name_link = name_span.find('a')\n",
        "                if name_link:\n",
        "                    name = name_link.text.strip()\n",
        "                else:\n",
        "                    name = name_span.text.strip()\n",
        "                research_area = research_area_span.text.strip()\n",
        "\n",
        "                cursor.execute(\"INSERT INTO teachers (url, name, research_area, method) VALUES (?, ?, ?, ?)\",\n",
        "                               (url, name, research_area, 'selenium' if use_selenium else 'requests'))\n",
        "                all_teacher_research_areas_txt += f\"{name}：{research_area}\\n\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"爬取 {url} 時發生錯誤 (使用 {'Selenium' if use_selenium else 'requests'})：{e}\\n\"\n",
        "        print(error_message)\n",
        "        all_teacher_research_areas_txt += error_message + \"\\n\"\n",
        "\n",
        "    all_teacher_research_areas_txt += \"\\n\"\n",
        "    conn.commit()\n",
        "    time.sleep(1)\n",
        "\n",
        "if use_selenium and driver:\n",
        "    driver.quit()\n",
        "\n",
        "with open(txt_filename, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(all_teacher_research_areas_txt)\n",
        "\n",
        "conn.close()\n",
        "\n",
        "print(f\"所有網頁的老師專長已儲存到 {txt_filename} 檔案中。\")\n",
        "print(f\"所有網頁的老師專長也已儲存到 SQLite 資料庫 {db_filename} 中。\")"
      ]
    },
    {
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "db_filename = \"teacher_research_areas_combined.db\"\n",
        "conn = sqlite3.connect(db_filename)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT * FROM teachers\")\n",
        "results = cursor.fetchall()\n",
        "print(\"所有資料：\", results)\n",
        "\n",
        "df = pd.read_sql_query(\"SELECT * FROM teachers\", conn)\n",
        "print(\"\\n使用 Pandas DataFrame 顯示資料：\")\n",
        "print(df)\n",
        "\n",
        "conn.close()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "y3FvAScH4VHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}